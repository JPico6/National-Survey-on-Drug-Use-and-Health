{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the National Survey of Health\n",
    "\n",
    "## Jason Piccone, Ph.D.\n",
    "\n",
    "## Part I: Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pandas import DataFrame\n",
    "from matplotlib import style \n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "path = \"/home/paco/Documents/data science/DS projects/national survey on drug use and health 2012/ICPSR_34933/DS0001/\"\n",
    "var_threshold = 0.05  # will remove features with less than 5% variance \n",
    "f_name = 'Data.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df =  pd.read_csv(path+f_name, sep=\"\\t\")\n",
    "\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic feature reduction/management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. focus on just the adult population\n",
    "df = df.loc[df['CATAG6'] != 1]\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "    \n",
    "# 2. Only some features are relevant for the adult population:\n",
    "adult_features = ['RSKPKCIG', 'RSKMJOCC', 'RKTRYLSD', 'RKTRYHER', \n",
    "'RKCOCOCC', 'RK5ALWK', 'RSKDIFMJ', 'RKDIFLSD', 'RKDIFCOC', 'RKDIFCRK', 'RKFQDNGR', 'RKFQRSKY', 'RKFQPBLT', 'RKFQDBLT', 'NMERTMT2', 'SNYSELL', 'SNYSTOLE', 'SNYATTAK',\n",
    "'SNFAMJEV', 'SNRLGSVC', 'SNRLGIMP', 'SNRLDCSN', 'SNRLFRND', 'DSTNRV30', 'DSTHOP30', 'DSTRST30',\n",
    "'DSTCHR30', 'DSTEFF30', 'DSTNGD30', 'IRHHSIZ2', 'IRKI17_2', 'IRHH65_2', 'IRFAMSZ2', 'IRKIDFA2',\n",
    "'IRPINC3', 'IRFAMIN3', 'AGE2', 'HEALTH', 'IREDUC2', 'CIGEVER', 'SNFEVER', 'CIGAREVR', \n",
    "'ALCEVER', 'MJEVER', 'COCEVER', 'CRKEVER', 'PCP', 'PEYOTE', 'MESC', 'PSILCY', 'ECSTASY',\n",
    "'HALNOLST', 'AMYLNIT', 'CLEFLU', 'GAS', 'GLUE', 'ETHER', 'SOLVENT', 'LGAS', 'NITOXID', 'SPPAINT',\n",
    "'AEROS', 'INHNOLST', 'DARVTYLC', 'PERCTYLX', 'ANLNOLST', 'KLONOPIN', 'XNAXATVN', 'VALMDIAZ', \n",
    "'TRNEVER', 'METHDES', 'DIETPILS', 'RITMPHEN', 'STMNOLST', 'STMEVER', 'SEDEVER', 'ADDERALL',\n",
    "'AMBIEN', 'COLDMEDS', 'KETAMINE', 'RSKSELL', 'BOOKED', 'PROBATON', 'TXEVER', 'INHOSPYR',\n",
    "'AUINPYR', 'AUOPTYR', 'AURXYR', 'AUUNMTYR', 'SUICTHNK', 'ADDPREV', 'IRFAMSOC', \n",
    "'MEDICARE', 'PRVHLTIN', 'HLCNOTYR', 'SERVICE', 'IRSEX', 'SCHENRL', \n",
    "'IRMARIT', 'NEWRACE2', 'EMPSTATY','CATAG6',\n",
    "'COUTYP2']\n",
    "\n",
    "\n",
    "df = df[adult_features]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 10) \n",
    "\n",
    "# do a quick quality check of the remaining features\n",
    "for feature in df.iloc[:, :2]:   # selecting just a subset for presentational purposes\n",
    "\n",
    "\n",
    "    print('**************************************\\n')\n",
    "    print(feature + ' unique values = ' + str(df[feature].unique()))           \n",
    "    print(feature + ' value counts = ' + str(df[feature].value_counts())+'\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Significant recoding is necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to recode multiple variables\n",
    "\n",
    "def restructure_features(df):\n",
    "    #(a) Convert the following variables from 3 (logically assigned \"yes\") to 1 (\"yes)\n",
    "    vars1 = ['PCP', 'PEYOTE', 'PSILCY', 'ECSTASY', 'AMYLNIT', 'CLEFLU', 'GAS', 'GLUE', 'ETHER', 'NITOXID',\n",
    "             'AEROS', 'DARVTYLC', 'PERCTYLX', 'KLONOPIN', \n",
    "             'METHDES', 'DIETPILS', 'RITMPHEN',  'BOOKED']\n",
    "             \n",
    "    for col in vars1:\n",
    "        df.loc[df[col] == 3, col].copy = 1\n",
    "\n",
    "    #(c) Convert 4 (\"No, logically assigned\") =2 (\"no\")\n",
    "    vars3 = ['ANLNOLST', 'STMNOLST'] \n",
    "    for col in vars3:\n",
    "        df.loc[df[col] == 4, col].copy = 2\n",
    "\n",
    "\n",
    "    #(d) Convert 81 (\"never used X type of drug, logically assigned\" and 91 (\"never used \n",
    "    # X type of drug\") = 2 (\"no\")\n",
    "    vars4 = ['TRNEVER', 'STMEVER', 'SEDEVER'] \n",
    "    for col in vars4:\n",
    "        df.loc[df[col] == 81, col].copy = 2\n",
    "    for col in vars4:\n",
    "        df.loc[df[col] == 91, col].copy = 2\n",
    "   \n",
    "       \n",
    "    #(h) Convert SCHENRL 3, 5, 11 (\"Yes, logically assigned\") = yes(1)\n",
    "    df['SCHENRL'][df.SCHENRL == 3].copy = 1\n",
    "    df['SCHENRL'][df.SCHENRL == 5].copy = 1\n",
    "    df['SCHENRL'][df.SCHENRL == 11].copy = 1\n",
    "\n",
    "    \n",
    "    #(i) Convert 91 (\"Ever used\") -> 2 (\"no\") \n",
    "    vars7 = ['CRKEVER', 'PCP', 'PEYOTE', 'MESC', 'PSILCY', 'ECSTASY', 'HALNOLST', 'AMYLNIT', 'CLEFLU', 'GAS', 'GLUE', 'ETHER',\n",
    "      'SOLVENT', 'LGAS', 'NITOXID', 'SPPAINT', 'AEROS', 'INHNOLST', 'PERCTYLX', 'DARVTYLC',\n",
    "      'ANLNOLST', 'KLONOPIN', 'XNAXATVN', 'VALMDIAZ', 'TRNEVER', 'METHDES', 'DIETPILS', \n",
    "      'RITMPHEN', 'STMNOLST', 'STMEVER', 'SEDEVER']  \n",
    "    for col in vars7:\n",
    "        df.loc[df[col] == 91, col].copy = 2  \n",
    "    \n",
    "      \n",
    "    #onvert 81 (\"Never used X type of drug\")-> 2(\"No\")\n",
    "    vars8 = ['PERCTYLX', 'DARVTYLC', 'ANLNOLST', 'KLONOPIN', 'XNAXATVN',\n",
    "        'VALMDIAZ', 'TRNEVER', 'METHDES', 'DIETPILS', 'RITMPHEN', 'STMNOLST', 'STMEVER', 'SEDEVER']      \n",
    "    for col in vars8:\n",
    "        df.loc[df[col] == 81, col].copy = 2\n",
    "\n",
    "    #(j) Convert 94, 97 and 99 to Nan\n",
    "    #df = df.replace(94, np.nan)\n",
    "    #df = df.replace(97, np.nan)\n",
    "    #df = df.replace(99, np.nan)\n",
    "    df.where(df < 80, np.nan, inplace=True)\n",
    "\n",
    "\n",
    "    return(df)\n",
    "\n",
    "# Apply feature cleaning:\n",
    "df_cleaned = restructure_features(df)\n",
    "print(df_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data visualization examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "style.use('ggplot')\n",
    "\n",
    "vars = ['CIGEVER','COCEVER']   #just doing two for demonstration purposes\n",
    "\n",
    "for var in vars:\n",
    "    \n",
    "    if var == 'CIGEVER':\n",
    "        title = 'Smoked a Cigarette'\n",
    "    else:\n",
    "        title = 'Used Cocaine'\n",
    "    \n",
    "    df_cleaned3 = df_cleaned[var]\n",
    "    df_cleaned3.dropna(inplace=True)\n",
    "    fig = plt.figure()    \n",
    "    counts = (Counter(df_cleaned3)).values()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    objects = ('Yes','No')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    plt.bar(y_pos, counts, align='center', alpha=0.5, width=.5)\n",
    "    ax1.set_xticks([0,1])    \n",
    "    ax1.set_xticklabels(objects, rotation=0, fontsize=13)\n",
    "    ax1.set_title('Have You Ever {}'.format(title))\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Standardize quantitative variables, and dummy code qualitative (where necessary). \n",
    "\n",
    "def standardize_features(df):\n",
    "    \n",
    "    #split dataframe into quantitative data and categorical data\n",
    "    \n",
    "    #1 standardize quantitative variables:\n",
    "    quant_vars = [  \n",
    "    'RSKPKCIG', 'RSKMJOCC', 'RKTRYLSD', \n",
    "    'RKTRYHER', 'RKCOCOCC', 'RK5ALWK', 'RSKDIFMJ', 'RKDIFLSD', 'RKDIFCOC', 'RKDIFCRK',  \n",
    "    'RKFQDNGR', 'RKFQRSKY', 'RKFQPBLT', 'RKFQDBLT', 'NMERTMT2', 'SNYSELL', 'SNYSTOLE', \n",
    "    'SNYATTAK', 'SNFAMJEV', 'SNRLGSVC', 'SNRLGIMP', 'SNRLDCSN', 'SNRLFRND', 'DSTNRV30', \n",
    "    'DSTHOP30','DSTRST30', 'DSTCHR30', 'DSTEFF30','DSTNGD30', 'IRHHSIZ2', 'IRKI17_2', \n",
    "    'IRHH65_2', 'IRFAMSZ2', 'IRKIDFA2', 'IRPINC3', 'IRFAMIN3', 'AGE2', 'HEALTH', 'IREDUC2']\n",
    "\n",
    "    # assemble the quantitative variables, and drop na\n",
    "    dfQuant = df[quant_vars]\n",
    "    dfQuant.dropna(inplace=True)\n",
    "    dfQuant = preprocessing.scale(dfQuant)\n",
    "    dfQuant = pd.DataFrame(data=dfQuant, columns=quant_vars)\n",
    "    \n",
    "\n",
    "    #2 recode binary categorical variables:\n",
    "    cat_features = ['CIGEVER','SNFEVER','CIGAREVR','ALCEVER','MJEVER','COCEVER','CRKEVER',\n",
    "    'PCP','PEYOTE','MESC','PSILCY','ECSTASY','HALNOLST','AMYLNIT','CLEFLU', 'GAS','GLUE',\n",
    "    'ETHER','SOLVENT','LGAS','NITOXID','SPPAINT','AEROS','INHNOLST','DARVTYLC', 'PERCTYLX', \n",
    "    'ANLNOLST', 'KLONOPIN', 'XNAXATVN', 'VALMDIAZ', 'TRNEVER', 'METHDES', 'DIETPILS', 'RITMPHEN', \n",
    "    'STMNOLST', 'STMEVER', 'SEDEVER','ADDERALL', 'AMBIEN', 'COLDMEDS', 'KETAMINE', 'RSKSELL', \n",
    "    'BOOKED', 'PROBATON','TXEVER', 'INHOSPYR', 'AUINPYR','AUOPTYR', 'AURXYR', 'AUUNMTYR', \n",
    "    'SUICTHNK', 'ADDPREV', 'IRFAMSOC', 'MEDICARE', 'PRVHLTIN', 'HLCNOTYR',  'SERVICE', 'IRSEX', \n",
    "    'SCHENRL']\n",
    "    \n",
    "    # assemble the categorical variables\n",
    "    dfCat = df[cat_features]\n",
    "    dfCat = dfCat.replace(1,0)\n",
    "    dfCat = dfCat.replace(2,1)\n",
    "    \n",
    "    \n",
    "    #3 dummy code non-binary categorical variables \n",
    " \n",
    "    MARITAL = pd.get_dummies(df['IRMARIT'])\n",
    "    MARITAL.columns = ['MARRIED','WIDOWED','DIVORCED','NEVER_MARRIED']\n",
    "\n",
    "    RACE = pd.get_dummies(df['NEWRACE2'])\n",
    "    RACE.columns = ['WHITE','BLACK','NATIVEAM','PACISL','ASIAN','MULTIPLE','HISPANIC']\n",
    "\n",
    "    EMPLOY = pd.get_dummies(df['EMPSTATY'])\n",
    "    EMPLOY.columns =['FULLTIME','PARTTIME','UNEMPLOYED','OTHER'] #,'EMPLOYMENT_SKIPPED']\n",
    "\n",
    "    AGECAT = pd.get_dummies(df['CATAG6'])\n",
    "    AGECAT.columns =['AGE18_25','AGE26_34','AGE35_49','AGE50_64','AGE65']\n",
    "\n",
    "    COUNTY = pd.get_dummies(df['COUTYP2'])\n",
    "    COUNTY.columns = ['COUNTY_LARGE','COUNTY_SMALL','COUNTY_NONMETRO']\n",
    "    \n",
    "    # 4. Combine them back together\n",
    "    total_df = pd.concat([dfQuant, dfCat, MARITAL,RACE,EMPLOY,AGECAT,COUNTY], axis=1)\n",
    "    \n",
    "    # 5 Remove NA\n",
    "    total_df.dropna(inplace=True)\n",
    "    \n",
    "    # 6. Remove features with tiny variances\n",
    "    features_prior = total_df.shape[1]\n",
    "    def variance_threshold_selector(df, threshold=var_threshold):\n",
    "        selector = VarianceThreshold(threshold)\n",
    "        selector.fit(df)\n",
    "        \n",
    "        return(df[df.columns[selector.get_support(indices=True)]])\n",
    "\n",
    "    total_df = variance_threshold_selector(total_df,var_threshold)\n",
    "    \n",
    "    # print the change in features due to low variance\n",
    "    features_post = total_df.shape[1]\n",
    "    features_changed = features_prior - features_post\n",
    "    print('Features eliminated for lacking variance = {0} out of {1}'.format(features_changed,features_prior))\n",
    "\n",
    "        \n",
    "    return (total_df)\n",
    "\n",
    "\n",
    "combined_df = standardize_features(df_cleaned)\n",
    "print(combined_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save to file for use in part II\n",
    "combined_df.to_csv(path+'combined_df.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
