{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the National Survey of Health\n",
    "\n",
    "## Jason Piccone, Ph.D.\n",
    "\n",
    "## Part II: Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from matplotlib import style \n",
    "from sklearn import linear_model, decomposition\n",
    "from sklearn import metrics\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, roc_auc_score, mean_squared_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import csv\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = \"/national survey on drug use and health 2012/ICPSR_34933/DS0001/\"\n",
    "d_file = 'combined_df.csv'\n",
    "style.use('ggplot')\n",
    "\n",
    "rand_state = 42\n",
    "trees = 100 # number of trees in the random forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path+d_file)\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore target distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dv_plots(df):\n",
    "\n",
    "    #Respondent been arrested?\n",
    "    counts = Counter(df.BOOKED).values()\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    objects = ('Yes','No')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    plt.bar(y_pos, counts, align='center', alpha=0.5, width=.5)\n",
    "    ax1.set_xticks([0,1])    \n",
    "    ax1.set_xticklabels(objects, rotation=0, fontsize=13)\n",
    "    ax1.set_title('Have You Ever Been Arrested?')\n",
    "    plt.show()\n",
    "\n",
    "    # obviously far more people have not been booked, but this is still a fine variable\n",
    "    # to test on, as many cases include variable values that are infrequent\n",
    "\n",
    "    #Respondent overall health\n",
    "    ax=plt.subplot(111)\n",
    "    plt.hist(df.HEALTH, bins=5, alpha=0.5)  \n",
    "    ax.set_xticklabels(('Excellent', 'Very Good', 'Good','Fair', 'Poor'), fontsize=8)\n",
    "    ax.set_xticks([-0.80,0.10,0.90,1.80,2.70])\n",
    "    plt.title('Distribution of Overall Health Ratings')\n",
    "    plt.xlabel(\"Health Rating\", fontsize=16)  \n",
    "    plt.ylabel(\"Count\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    # positively skewed - most people are relatively healthy, with a few trailing off\n",
    "    # to fair and poor values\n",
    "\n",
    "dv_plots(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore feature distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_features(df):\n",
    "\n",
    "    '''explore demographic information:'''\n",
    "    #Respondent Sex\n",
    "    counts = Counter(df.IRSEX).values()\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    objects = ('Male','Female')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    plt.bar(y_pos, counts, align='center', alpha=0.5, width=.5)\n",
    "    ax1.set_xticks([0,1])    \n",
    "    ax1.set_xticklabels(objects, rotation=0, fontsize=13)\n",
    "    ax1.set_title('What is Your Gender?')\n",
    "    plt.show()\n",
    "\n",
    "    #Respondent marital status\n",
    "    cMarried = list(Counter(df.MARRIED).values())[1]\n",
    "    cDivorced = list(Counter(df.DIVORCED).values())[1]\n",
    "    cNeverM = list(Counter(df.NEVER_MARRIED).values())[1]\n",
    "    tMARRIED = [cMarried,cDivorced,cNeverM]\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    objects = ('Married','Divorced','Never Married')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    plt.bar(y_pos, tMARRIED, align='center', alpha=0.5, width=.5)\n",
    "    ax1.set_xticks([0,1,2,3])    \n",
    "    ax1.set_xticklabels(objects, rotation=0, fontsize=13)\n",
    "    ax1.set_title('What is Your Marital Status?')\n",
    "    plt.show()\n",
    "\n",
    "    #Respondent county size\n",
    "    cLarge = list(Counter(df.COUNTY_LARGE).values())[1]\n",
    "    cMedium = list(Counter(df.COUNTY_SMALL).values())[1]\n",
    "    cSmall = list(Counter(df.COUNTY_NONMETRO).values())[1]\n",
    "    tMETRO = [cLarge,cMedium,cSmall]\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    objects = ('Large','Medium','Small')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    plt.bar(y_pos, tMETRO, align='center', alpha=0.5, width=.5)\n",
    "    ax1.set_xticks([0,1,2])    \n",
    "    ax1.set_xticklabels(objects, rotation=0, fontsize=13)\n",
    "    ax1.set_title('What Type of County do you Live in?')\n",
    "    plt.show()\n",
    "\n",
    "    #Respondent employment status\n",
    "    cFull = list(Counter(df.FULLTIME).values())[1]\n",
    "    cPart = list(Counter(df.PARTTIME).values())[1]\n",
    "    cUne = list(Counter(df.UNEMPLOYED).values())[1]\n",
    "    cOther = list(Counter(df.OTHER).values())[1]\n",
    "    tEMPLOY = [cFull, cPart, cUne, cOther]\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    objects = ('Full-Time','Part-Time','Unemployed','Other')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    plt.bar(y_pos, tEMPLOY, align='center', alpha=0.5, width=.5)\n",
    "    ax1.set_xticks([0,1,2,3])    \n",
    "    ax1.set_xticklabels(objects, rotation=0, fontsize=13)\n",
    "    ax1.set_title('What Is Your Employment Status?')\n",
    "    plt.show()\n",
    "\n",
    "    #Respondent school status\n",
    "    cSCHOOL = list(Counter(df.SCHENRL).values())\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    objects = ('Yes','No')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    plt.bar(y_pos, cSCHOOL, align='center', alpha=0.5, width=.5)\n",
    "    ax1.set_xticks([0,1])    \n",
    "    ax1.set_xticklabels(objects, rotation=0, fontsize=13)\n",
    "    ax1.set_title('Are You Currently Enrolled in Any School?')\n",
    "    plt.show()\n",
    "\n",
    "    #Respondent income\n",
    "    ax=plt.subplot(111)\n",
    "    plt.hist(df.IRPINC3, bins=7, alpha=0.5)  \n",
    "    ax.set_xticklabels(('< 10k', '10-19k','20-29k','30-39k','40-49k','50-75k','75k+'), fontsize=8)\n",
    "    ax.set_xticks([-0.40,0.10,0.60,1.085,1.60,2.10,2.60])\n",
    "    plt.title(\"Respondent's Income Level\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "plot_features(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to partition the data\n",
    "def split_data(df,y):\n",
    "        # param df = the dataframe to partition\n",
    "        # param y = one of the two possible target variables\n",
    "\n",
    "        '''divide sample into train and test'''      \n",
    "        y = df[y]\n",
    "        X = df.drop(['BOOKED','HEALTH'], axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=rand_state)\n",
    "\n",
    "        return(X_train, X_test, y_train, y_test)\n",
    "    \n",
    "    \n",
    "def run_rf(df,y):\n",
    "    \n",
    "    # param df: dataframe\n",
    "    # param y: the target variable (either 'BOOKED' or 'HEALTH')\n",
    "\n",
    "\n",
    "    if y == 'BOOKED':\n",
    "        rf = RandomForestClassifier(n_estimators=trees)\n",
    "    else:\n",
    "        rf = RandomForestRegressor(n_estimators=trees)\n",
    "            \n",
    "    # collect the data partitions\n",
    "    X_train, X_test, y_train, y_test = split_data(df,y)\n",
    "\n",
    "\n",
    "    # run the random forest model\n",
    "    def run_rf(X_train, X_test, y_train, y_test):\n",
    "\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        # assess model accuracy for 'booked' \n",
    "        if y == 'BOOKED':\n",
    "            \n",
    "            disbursed = rf.predict_proba(X_train)\n",
    "\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(y_train, disbursed[:,1])\n",
    "            print('Random forest predicting Booked AUC (train set) = ' + str(metrics.auc(fpr, tpr)))\n",
    "\n",
    "            #plot auc\n",
    "            plt.plot(fpr,tpr)\n",
    "            plt.xlabel('False Positives')\n",
    "            plt.ylabel('True Positives')\n",
    "            plt.title('AUC: Have You Ever Been Arrested-Training Set')\n",
    "            plt.show()\n",
    "\n",
    "            #how accurate on the test set\n",
    "            disbursed = rf.predict_proba(X_test)\n",
    "            fpr, tpr, thresholds = metrics.roc_curve(y_test, disbursed[:,1])\n",
    "            print('Random forest predicting Booked AUC (test set) = ' + str(metrics.auc(fpr, tpr)))\n",
    "\n",
    "            #plot auc\n",
    "            plt.plot(fpr,tpr)\n",
    "            plt.xlabel('False Positives')\n",
    "            plt.ylabel('True Positives')\n",
    "            plt.title('AUC: Have You Ever Been Arrested-Test Set')\n",
    "            plt.show()\n",
    "\n",
    "            disbursed = rf.predict(X_test)     \n",
    "            print('test set confusing matrix:')\n",
    "            print(confusion_matrix(disbursed, y_test))\n",
    "\n",
    "            def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "                plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "                plt.title(title)\n",
    "                plt.colorbar()\n",
    "                plt.tight_layout()\n",
    "                plt.ylabel('True label')\n",
    "                plt.xlabel('Predicted label')\n",
    "                plt.show()\n",
    "\n",
    "\n",
    "            cm = confusion_matrix(y_test, disbursed)\n",
    "            np.set_printoptions(precision=2)\n",
    "            print('Confusion matrix, without normalization')\n",
    "            print(cm)\n",
    "            plt.figure()\n",
    "            plot_confusion_matrix(cm)\n",
    "            '''we can see we predict people who have not been booked very well, but we also predict\n",
    "            too many people to not be booked (quite a few false negatives). '''\n",
    "\n",
    "\n",
    "            # Normalize the confusion matrix by row (i.e by the number of samples\n",
    "            # in each class)\n",
    "            cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "            print('Normalized confusion matrix')\n",
    "            print(cm_normalized)\n",
    "            plt.figure()\n",
    "            plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')\n",
    "         \n",
    "        # assess model accuracy for 'health' \n",
    "        else:\n",
    "            p1 = rf.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, p1)\n",
    "            print('root mean squared error = '+str(math.sqrt(mse)))\n",
    "            \n",
    "\n",
    "        '''variable importance for the RF'''\n",
    "        importances = rf.feature_importances_\n",
    "        std = np.std([tree.feature_importances_ for tree in rf.estimators_],\n",
    "                     axis=0)\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "\n",
    "        # plot the top 10 features\n",
    "        top10 = sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), X_train.columns), \n",
    "                     reverse=True)[:10]\n",
    "        top10 = pd.DataFrame(top10)\n",
    "\n",
    "        objects = top10[1]\n",
    "        plt.bar(range(top10.shape[0]), top10[0], align=\"center\", alpha=0.5)\n",
    "        plt.xticks(range(10), objects, rotation='vertical')\n",
    "        plt.title('Feature Importance Predicting {0}'.format(y))\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    run_rf(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run random forest classifier on 'have you ever been booked?'\n",
    "run_rf(df,'BOOKED')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run random forest regressor on 'how is your overall health?'\n",
    "run_rf(df,'HEALTH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Analysis\n",
    "\n",
    "One alternative is to perform a principle component analysis (PCA) to combine features. This\n",
    "will be especially effective if the components that emerge are actually interpretable, which\n",
    "is not gaurantted! \n",
    "\n",
    "We could also explore these variables in greater detail. For example, TXEVER (ever received\n",
    "treatment for drugs/alcohol) could be further explored with the feature AUMOTVYR,\n",
    "which is what prompted people to get treatment for past mental health issues -- such as whether\n",
    "they did so voluntarily or not. But it's unclear if people who were forced to receive \n",
    "mental health treatment where treated for drug/alcohol abuse or not.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def booked(df):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_data(df,'BOOKED')\n",
    "\n",
    "\n",
    "    #How many components is ideal? Let's first test how much variance is accounted for:\n",
    "    # Plot the PCA spectrum\n",
    "    pca = decomposition.PCA()\n",
    "    pca.fit(X_train)\n",
    "    plt.figure(1, figsize=(4, 3))\n",
    "    plt.clf()\n",
    "    plt.axes([.2, .2, .7, .7])\n",
    "    plt.plot(pca.explained_variance_, linewidth=2)\n",
    "    plt.title('Components by Variance Explained', fontsize=13)\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Explained Variance')\n",
    "    plt.show()\n",
    "\n",
    "    #After 10 components, each additional component explains less than .5% of the total variance.\n",
    "    #However, the total variance explained increases up to 50 components. We can try both.\n",
    "    \n",
    "    # fits PCA, transforms data and fits the decision tree classifier\n",
    "    # on the transformed data\n",
    "    pipe = Pipeline([('pca', PCA(n_components=40)),\n",
    "                     ('tree', RandomForestClassifier(n_estimators=100))])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    disbursed = pipe.predict_proba(X_test)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, disbursed[:,1])\n",
    "    print('New AUC = ' + str(metrics.auc(fpr, tpr))) \n",
    "\n",
    "booked(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# trying the pca analysis for the overall health outcome:\n",
    "    \n",
    "def pca_health(df):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_data(df,'HEALTH')\n",
    "\n",
    "\n",
    "    pipe = Pipeline([('pca', PCA(n_components=40)),\n",
    "                     ('tree', RandomForestRegressor(n_estimators=trees))])\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    disbursed = pipe.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, disbursed)\n",
    "    #.834\n",
    "    print('root mean squared error = ' + str(math.sqrt(mse)))\n",
    "\n",
    "    \n",
    "pca_health(df)\n",
    "\n",
    "\"\"\"\n",
    "theoretically using PCA could improve the model's predictive ability as it may\n",
    "reduced overfitting - by reducing the number of features in an orthogonal manner,\n",
    "we were able to remove variables which just added noise to the train model - so the random\n",
    "forest trained on that noise in the benchmark model. In addition, we gain power through\n",
    "the reduction of dimensionality. Nevertheless, PCA depricated the model slightly\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(path+'df2.csv', index=False)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
